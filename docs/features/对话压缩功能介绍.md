# 对话压缩功能介绍

## 功能概述

当对话历史过长时，每次发送消息都需要将大量历史记录发送给 AI，这会导致：
- 响应速度变慢
- Token 消耗增加
- 成本上升

对话压缩功能通过 AI 生成摘要来解决这个问题：**将历史对话压缩为简洁的摘要，减少后续请求的上下文大小，同时保留完整的历史记录供您查看**。

## 使用方式

### 触发压缩

1. **查看对话大小**：在输入框上方会显示当前对话的统计信息（消息数、Token 数）
2. **压缩提示**：当对话内容较多时，系统会自动显示"建议压缩对话"提示
3. **手动压缩**：点击"压缩对话"按钮启动压缩流程

### 压缩过程

压缩过程包含以下步骤：

1. **系统分析对话**：自动计算需要压缩的消息范围，默认保留最近 4 条消息
2. **创建压缩请求**：在对话中插入一条特殊的压缩请求消息（蓝色样式）
3. **AI 生成摘要**：AI 会分析历史对话并生成详细摘要（约 500-1000 字）
4. **保存摘要**：摘要作为压缩响应消息保存在对话中（琥珀色样式）

整个过程是流式的，您可以实时看到 AI 生成摘要的过程，也可以随时点击停止按钮中断压缩。

### 压缩后的对话

压缩完成后，对话中会出现两条特殊消息：

- **压缩请求**（蓝色）：显示压缩指令，前方有"以上内容已压缩"分界线
- **压缩响应**（琥珀色）：AI 生成的摘要，默认折叠状态，点击可展开查看

后续发送消息时，系统只会将压缩摘要和保留的消息发送给 AI，大幅减少上下文大小。

## 工作原理

### 压缩范围计算

假设当前有 100 条消息，压缩保留数为 4：

```
消息 1-96：待压缩的历史消息
消息 97-100：保留的最近消息
```

系统会将消息 1-96 的内容发送给 AI 进行压缩，生成一条摘要消息。

### 压缩边界

**压缩边界**是压缩摘要在对话中的位置，它决定了后续请求的上下文起点：

压缩前的请求上下文：
```
系统提示词 + 消息 1-100 + 用户新输入
（约 20,000 tokens）
```

压缩后的请求上下文：
```
系统提示词 + 压缩摘要 + 消息 97-100 + 用户新输入
（约 3,000 tokens）
```

### 多次压缩

当对话再次变长时，您可以再次压缩。系统会从**上一次的压缩摘要**开始，生成"摘要的摘要"：

**第一次压缩**（100 条消息）：
- 压缩消息 1-96，生成摘要 A
- 保留消息 97-100

**第二次压缩**（假设又积累了 50 条，共 152 条）：
- 压缩"摘要 A + 消息 97-148"，生成摘要 B
- 保留消息 149-152

这种方式的优点：
- ✅ 持续减少上下文大小
- ✅ 利用 API 缓存（上次的摘要已缓存）
- ✅ 避免重复发送原始历史

注意事项：
- ⚠️ 多次压缩后可能丢失部分细节（摘要的摘要会更简化）
- 💡 如需保留完整历史，可在压缩前分叉对话

## UI 展示

### 消息样式

| 消息类型 | 样式标识 | 功能 |
|---------|---------|------|
| 压缩请求 | 蓝色边框 + 归档图标 | 显示压缩指令，前方有分界线 |
| 压缩响应 | 琥珀色边框 + 文档图标 | AI 生成的摘要，默认折叠 |

### 分界线

压缩请求前方会显示分界线，标识"以上内容已压缩"：

```
────── 以上内容已压缩 ──────
[压缩请求]
[压缩响应]
消息 97
消息 98
...
```

这让您清楚地知道哪些消息已经被压缩，哪些消息会直接发送给 AI。

### 折叠/展开

- **压缩请求**：始终显示为简短的"压缩请求"标签，不显示完整的压缩指令
- **压缩响应**：
  - 默认折叠，显示"压缩摘要（点击展开）"
  - 点击标题可展开/折叠
  - 流式生成过程中自动展开

### 对话统计

输入框上方显示的对话统计信息：
```
📊 当前上下文：5 条消息 | 约 3,000 tokens
```

如果对话未压缩，显示完整的消息数：
```
📊 当前上下文：100 条消息 | 约 20,000 tokens | ⚠️ 建议压缩对话
```

## 注意事项

### 压缩时机

- **建议压缩**：当对话超过 20 条消息或 10,000 tokens 时
- **必须压缩**：部分 API 有上下文长度限制（如 8,000 tokens），超出后会报错
- **可选压缩**：对话内容较多但未超限时，压缩可以加快响应速度

### 删除压缩消息

您可以删除压缩请求或压缩响应消息，系统会自动调整压缩边界：

- **删除压缩响应**：回退到上一个压缩点（如果存在），或发送所有历史消息
- **删除压缩请求**：不影响压缩响应，但会影响对话可读性

💡 **建议**：除非确实需要，否则不要删除压缩消息，这会导致上下文大小重新增加。

### 压缩质量

压缩摘要的质量取决于：
1. **AI 模型能力**：更强的模型生成的摘要更准确完整
2. **压缩指令**：可在设置中自定义压缩 Prompt，调整摘要风格和详细程度
3. **对话内容**：结构化的对话更容易生成高质量摘要

### 配置选项

您可以在设置页面调整以下参数：

| 设置项 | 默认值 | 说明 |
|-------|-------|------|
| 压缩保留消息数 | 4 | 压缩时保留的最近消息数量 |
| 压缩指令 | 系统默认 | 自定义 AI 生成摘要的 Prompt |

**压缩指令示例**（系统默认）：
```
请将以下对话内容压缩为一份详细的摘要（约500-1000字），需要保留：
1. 讨论的主要话题和结论
2. 重要的技术细节、代码片段或配置信息
3. 用户的关键需求和偏好
4. 待解决的问题或后续任务

{messages}

直接输出摘要内容，不要加标题或格式说明。
```

您可以根据需求调整摘要的详细程度、侧重点等。

## 最佳实践

1. **定期压缩**：当对话超过 20 条消息时进行压缩，避免累积过多历史
2. **分叉保存**：在压缩前可以分叉对话，保留完整的历史记录作为备份
3. **合理保留**：默认保留 4 条消息已足够，不建议设置过大（会减弱压缩效果）
4. **检查摘要**：压缩后展开查看摘要，确认重要信息未丢失
5. **多次压缩**：对于超长对话（100+ 条消息），可以多次压缩以持续优化上下文

## 常见问题

**Q: 压缩后 AI 会"忘记"之前的对话吗？**

A: 不会。压缩摘要包含了历史对话的关键信息，AI 仍然能够理解上下文。但摘要会简化细节，如果需要讨论非常具体的历史内容，可能需要手动补充。

**Q: 压缩会影响对话质量吗？**

A: 影响很小。现代 AI 模型擅长理解摘要内容，压缩后的对话质量与压缩前基本一致。但多次压缩后可能会丢失一些细节。

**Q: 压缩需要消耗 tokens 吗？**

A: 是的。压缩过程会调用 AI 生成摘要，这会消耗 tokens（约等于待压缩消息的大小）。但后续每次对话都会节省大量 tokens，总体上是划算的。

**Q: 可以撤销压缩吗？**

A: 可以。删除压缩响应消息即可回退到上一个压缩点，或者删除所有压缩消息恢复发送完整历史。但这会导致上下文大小重新增加。

**Q: 压缩保留数设置多少合适？**

A: 默认的 4 条已足够。这样既能保留最近的上下文（通常是 2 轮对话），又能最大化压缩效果。设置过大（如 10 条以上）会减弱压缩的意义。
