# 模型可用性测试功能介绍

## 功能概述

一键批量测试所有上游配置的模型可用性，快速识别失效模型并进行批量处理。

**解决的痛点**：上游和模型配置经常失效，每次使用时才发现问题，需要反复切换尝试。通过定期批量测试，提前发现问题模型。

## 核心功能

### 1. 批量测试

- **按分类测试**：支持分别测试对话、绘图、视频三类模型
- **并发控制**：可设置同时测试的模型数量（1-10），避免请求过于密集
- **完整验证**：异步模型（Midjourney、视频）会等待任务完全生成，而非仅验证提交成功

### 2. 自定义测试参数

- **提示词**：可自定义测试用的提示词，默认提供合理的测试提示词
- **关键词验证**：可设置期望响应中包含的关键词，用于验证模型是否正常工作
- **超时设置**：可配置单个模型的最大等待时间

### 3. 实时反馈

- **进度显示**：显示整体测试进度（已完成数/总数）
- **状态更新**：每个模型独立显示状态（等待中/测试中/成功/失败），支持多个模型同时处于测试中状态
- **错误信息**：失败时显示具体错误原因

### 4. 结果管理

- **筛选查看**：可按状态筛选（全部/成功/失败/未测试）
- **历史记录**：测试结果保存到数据库，可查看历史测试记录
- **趋势分析**：可查看模型的稳定性趋势（多次测试的成功率）

### 5. 批量操作

- **批量选择**：支持全选、按状态选择（如"选择所有失败的模型"）
- **批量禁用**：一键禁用选中的模型
- **批量删除**：一键删除选中的模型
- **批量重试**：一键重新测试选中的模型

## 页面布局

```
┌─────────────────────────────────────────────────────────────────────┐
│  模型可用性测试                                           [开始测试] │
├─────────────────────────────────────────────────────────────────────┤
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ 测试配置                                                     │   │
│  │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐             │   │
│  │ │ 分类: 对话 ▼│ │ 并发数: 3 ▼│ │ 超时: 60s ▼│             │   │
│  │ └─────────────┘ └─────────────┘ └─────────────┘             │   │
│  │                                                              │   │
│  │ 提示词: [请用一句话介绍你自己                           ]   │   │
│  │ 验证关键词: [AI, 助手, 模型                             ]   │   │
│  └─────────────────────────────────────────────────────────────┘   │
├─────────────────────────────────────────────────────────────────────┤
│  测试进度: ████████░░░░░░░░ 12/25  (并发中: 3)                      │
├─────────────────────────────────────────────────────────────────────┤
│  ┌──────────────────────────────────────────────────────────────┐  │
│  │ 筛选: [全部] [成功 8] [失败 4] [未测试 13]                   │  │
│  │ 操作: [全选] [选择失败] [批量禁用] [批量删除] [批量重试]     │  │
│  └──────────────────────────────────────────────────────────────┘  │
├─────────────────────────────────────────────────────────────────────┤
│  ┌────────────────────────────────────────────────────────────────┐│
│  │ □ 上游A                                                        ││
│  │   ├─ ✅ GPT-4o          对话   1.2s   "我是一个AI助手..."     ││
│  │   ├─ ⏳ Claude-3        对话   测试中...                       ││
│  │   ├─ ❌ Gemini Pro      对话   超时   连接超时                 ││
│  │   └─ ⏳ DALL-E 3        绘图   测试中... 生成进度 45%          ││
│  │                                                                ││
│  │ □ 上游B                                                        ││
│  │   ├─ ✅ Midjourney      绘图   45.2s  [查看图片]               ││
│  │   ├─ ⏳ Flux            绘图   测试中...                       ││
│  │   └─ ◐ GPT-4           对话   等待中                          ││
│  └────────────────────────────────────────────────────────────────┘│
├─────────────────────────────────────────────────────────────────────┤
│  历史记录                                                           │
│  ┌────────────────────────────────────────────────────────────────┐│
│  │ 2024-01-15 14:30  对话模型  成功 12/15  失败 3                 ││
│  │ 2024-01-14 10:00  绘图模型  成功 8/10   失败 2                 ││
│  │ 2024-01-13 09:00  全部模型  成功 20/28  失败 8                 ││
│  └────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────┘
```

## 页面区域说明

### 顶部：测试配置区

| 配置项 | 说明 | 默认值 |
|-------|------|-------|
| 分类 | 选择要测试的模型类型 | 对话 |
| 并发数 | 同时测试的模型数量 | 3 |
| 超时时间 | 单个模型最大等待时间 | 对话 30s / 绘图 120s / 视频 300s |
| 提示词 | 发送给模型的测试内容 | 按分类提供默认值 |
| 验证关键词 | 期望响应包含的关键词（可选） | 空 |

### 中部：进度条

- 显示整体进度（已完成/总数）
- 显示当前并发数（正在测试的模型数量）

### 筛选与操作栏

- **筛选按钮**：按状态筛选，显示各状态的数量
- **批量操作**：对选中的模型执行操作

### 主体：模型列表

按上游分组显示所有模型，每个模型显示：
- 复选框（用于批量选择）
- 状态图标（○未测试 / ◐等待中 / ⏳测试中 / ✅成功 / ❌失败）
- 模型名称
- 模型分类标签
- 响应时间（成功时）
- 响应预览或错误信息

### 底部：历史记录

显示最近的测试记录，点击可查看详情。

## 默认测试提示词

| 分类 | 默认提示词 |
|-----|-----------|
| 对话 | "请用一句话介绍你自己" |
| 绘图 | "a cute cat, simple illustration" |
| 视频 | "a cat walking slowly" |

## 测试流程

1. 用户选择要测试的模型分类
2. 配置并发数、超时时间、提示词（可选）
3. 点击「开始测试」
4. 系统按并发数批量发起测试请求
5. 实时更新每个模型的测试状态
6. 测试完成后，用户可筛选查看结果
7. 对失败的模型进行批量处理（禁用/删除/重试）
8. 测试结果自动保存到数据库

## 数据存储

### 测试记录表

| 字段 | 类型 | 说明 |
|-----|------|------|
| id | number | 主键 |
| userId | number | 用户ID |
| category | string | 测试的模型分类 |
| totalCount | number | 测试模型总数 |
| successCount | number | 成功数量 |
| failedCount | number | 失败数量 |
| createdAt | datetime | 测试时间 |

### 测试结果表

| 字段 | 类型 | 说明 |
|-----|------|------|
| id | number | 主键 |
| testRecordId | number | 关联测试记录 |
| aimodelId | number | 模型ID |
| status | string | 成功/失败 |
| responseTime | number | 响应时间（毫秒） |
| responsePreview | string | 响应内容预览（前100字符） |
| errorMessage | string | 错误信息（失败时） |
| createdAt | datetime | 测试时间 |

## 交互细节

### 测试中的交互

- 测试进行中时，「开始测试」按钮变为「停止测试」
- 点击停止后，已发起的请求会继续完成，但不再发起新请求
- 可以随时修改筛选条件查看已完成的结果

### 批量操作确认

- 批量禁用：显示确认对话框，列出将被禁用的模型
- 批量删除：显示确认对话框，提示删除后可在回收站恢复
- 批量重试：直接开始重新测试，无需确认

### 响应预览

- 对话模型：显示响应文本的前 100 个字符
- 绘图模型：显示缩略图，点击可查看大图
- 视频模型：显示视频封面，点击可播放

## 页面路由

```
/settings/model-test
```

## 相关页面

- [上游和模型配置](./上游和模型配置.md) - 管理上游和模型
